nohup: ignoring input
Compose(
    <built-in function array>
    Lambda()
    ToTensor()
    <class 'torch.FloatTensor'>
    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))
)
epoch 120/500 over, loss_G,loss_D= 5.2824931144714355,0.8062084317207336
1.train_bodystick.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  losses, out_img = big_model(torch.tensor(lbl_sample,dtype=torch.float32, device=torch.device('cuda:0'))
1.train_bodystick.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  ,torch.tensor(in_img,dtype=torch.float32, device=torch.device('cuda:0'))
/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
epoch 121/500 over, loss_G,loss_D= 4.392658233642578,0.4393610954284668
epoch 122/500 over, loss_G,loss_D= 4.83616828918457,0.3551176190376282
epoch 123/500 over, loss_G,loss_D= 5.1079325675964355,0.2374589443206787
epoch 124/500 over, loss_G,loss_D= 5.498075008392334,0.1477975845336914
epoch 125/500 over, loss_G,loss_D= 5.111240386962891,0.3884269595146179
epoch 126/500 over, loss_G,loss_D= 4.967432022094727,0.3277862071990967
epoch 127/500 over, loss_G,loss_D= 5.24644660949707,0.19249506294727325
epoch 128/500 over, loss_G,loss_D= 4.859554767608643,0.28390026092529297
epoch 129/500 over, loss_G,loss_D= 5.381824016571045,0.21691232919692993
epoch 130/500 over, loss_G,loss_D= 4.430335521697998,0.3761660158634186
epoch 131/500 over, loss_G,loss_D= 5.138507843017578,0.1128576397895813
epoch 132/500 over, loss_G,loss_D= 5.468354225158691,0.15776515007019043
epoch 133/500 over, loss_G,loss_D= 5.547245025634766,0.05997729301452637
epoch 134/500 over, loss_G,loss_D= 5.2941107749938965,0.3011956214904785
epoch 135/500 over, loss_G,loss_D= 5.348552703857422,0.2777456045150757
epoch 136/500 over, loss_G,loss_D= 5.248751163482666,0.25794535875320435
epoch 137/500 over, loss_G,loss_D= 4.825478553771973,0.20703938603401184
epoch 138/500 over, loss_G,loss_D= 5.281085014343262,0.22047847509384155
epoch 139/500 over, loss_G,loss_D= 4.976224422454834,0.22428780794143677
epoch 140/500 over, loss_G,loss_D= 5.10883903503418,0.19341737031936646
epoch 141/500 over, loss_G,loss_D= 5.155126571655273,0.15420663356781006
epoch 142/500 over, loss_G,loss_D= 5.301084518432617,0.1310305893421173
epoch 143/500 over, loss_G,loss_D= 5.293704986572266,0.129891037940979
epoch 144/500 over, loss_G,loss_D= 5.364225387573242,0.06580682098865509
epoch 145/500 over, loss_G,loss_D= 5.032588958740234,0.15559335052967072
epoch 146/500 over, loss_G,loss_D= 4.866580009460449,0.1173538789153099
epoch 147/500 over, loss_G,loss_D= 4.617397785186768,0.33079439401626587
epoch 148/500 over, loss_G,loss_D= 5.123003959655762,0.13903817534446716
epoch 149/500 over, loss_G,loss_D= 4.644084930419922,0.3624396324157715
epoch 150/500 over, loss_G,loss_D= 5.13752555847168,0.09254597127437592
epoch 151/500 over, loss_G,loss_D= 4.814353942871094,0.27033668756484985
epoch 152/500 over, loss_G,loss_D= 5.2527570724487305,0.29184216260910034
epoch 153/500 over, loss_G,loss_D= 5.083774566650391,0.10804258286952972
epoch 154/500 over, loss_G,loss_D= 5.460722923278809,0.09157020598649979
epoch 155/500 over, loss_G,loss_D= 5.142657279968262,0.07020625472068787
epoch 156/500 over, loss_G,loss_D= 4.919394493103027,0.13707520067691803
epoch 157/500 over, loss_G,loss_D= 4.870257377624512,0.117301344871521
epoch 158/500 over, loss_G,loss_D= 4.846030235290527,0.10463294386863708
epoch 159/500 over, loss_G,loss_D= 4.1318254470825195,0.3301598131656647
epoch 160/500 over, loss_G,loss_D= 4.104438781738281,0.25255388021469116
epoch 161/500 over, loss_G,loss_D= 5.131054878234863,0.10286995023488998
epoch 162/500 over, loss_G,loss_D= 4.908809185028076,0.10247638821601868
epoch 163/500 over, loss_G,loss_D= 5.155659198760986,0.11696192622184753
epoch 164/500 over, loss_G,loss_D= 4.247432231903076,0.3223227858543396
epoch 165/500 over, loss_G,loss_D= 5.063071250915527,0.05144566297531128
epoch 166/500 over, loss_G,loss_D= 4.787500381469727,0.08221164345741272
epoch 167/500 over, loss_G,loss_D= 4.759328842163086,0.20145446062088013
epoch 168/500 over, loss_G,loss_D= 5.530885696411133,0.11644532531499863
epoch 169/500 over, loss_G,loss_D= 4.489316940307617,0.16307467222213745
epoch 170/500 over, loss_G,loss_D= 5.189396858215332,0.1425493359565735
epoch 171/500 over, loss_G,loss_D= 5.037884712219238,0.04235927760601044
epoch 172/500 over, loss_G,loss_D= 5.490749359130859,0.22702401876449585
epoch 173/500 over, loss_G,loss_D= 4.954987049102783,0.1227039322257042
epoch 174/500 over, loss_G,loss_D= 6.38831901550293,2.3121917247772217
epoch 175/500 over, loss_G,loss_D= 5.1727800369262695,0.05024103820323944
epoch 176/500 over, loss_G,loss_D= 4.7954254150390625,0.0707433819770813
epoch 177/500 over, loss_G,loss_D= 5.334449768066406,0.1428067982196808
epoch 178/500 over, loss_G,loss_D= 4.486212253570557,0.18505746126174927
epoch 179/500 over, loss_G,loss_D= 4.609029769897461,0.06937102973461151
epoch 180/500 over, loss_G,loss_D= 4.999359130859375,0.04735858738422394
epoch 181/500 over, loss_G,loss_D= 4.900580406188965,0.10329534858465195
epoch 182/500 over, loss_G,loss_D= 4.531974792480469,0.18115919828414917
epoch 183/500 over, loss_G,loss_D= 4.601957321166992,0.20738819241523743
epoch 184/500 over, loss_G,loss_D= 5.03972053527832,0.027209600433707237
epoch 185/500 over, loss_G,loss_D= 4.664060115814209,0.19363687932491302
epoch 186/500 over, loss_G,loss_D= 5.192206859588623,0.07286924123764038
epoch 187/500 over, loss_G,loss_D= 4.411257266998291,0.12540070712566376
epoch 188/500 over, loss_G,loss_D= 5.0269598960876465,0.013596243225038052
epoch 189/500 over, loss_G,loss_D= 4.9382758140563965,0.13007661700248718
epoch 190/500 over, loss_G,loss_D= 4.832128047943115,0.028517048805952072
epoch 191/500 over, loss_G,loss_D= 4.713630676269531,0.07288007438182831
epoch 192/500 over, loss_G,loss_D= 4.231088161468506,0.3120337128639221
epoch 193/500 over, loss_G,loss_D= 4.937398433685303,0.055151645094156265
epoch 194/500 over, loss_G,loss_D= 4.623856544494629,0.2911376655101776
epoch 195/500 over, loss_G,loss_D= 5.351324081420898,0.03300420194864273
epoch 196/500 over, loss_G,loss_D= 5.113833904266357,0.04924267530441284
epoch 197/500 over, loss_G,loss_D= 4.725852012634277,0.05177883803844452
epoch 198/500 over, loss_G,loss_D= 5.310344696044922,0.06688578426837921
epoch 199/500 over, loss_G,loss_D= 4.996187210083008,0.06213501840829849
epoch 200/500 over, loss_G,loss_D= 4.842259407043457,0.036754123866558075
epoch 201/500 over, loss_G,loss_D= 4.596226215362549,0.09701919555664062
epoch 202/500 over, loss_G,loss_D= 4.80660343170166,0.016468238085508347
epoch 203/500 over, loss_G,loss_D= 4.619651794433594,0.08787049353122711
epoch 204/500 over, loss_G,loss_D= 4.533630847930908,0.07119710743427277
epoch 205/500 over, loss_G,loss_D= 4.964495658874512,0.05802479386329651
epoch 206/500 over, loss_G,loss_D= 5.0565571784973145,0.09690872579813004
epoch 207/500 over, loss_G,loss_D= 5.086754322052002,0.05253458023071289
epoch 208/500 over, loss_G,loss_D= 5.088242530822754,0.027054978534579277
epoch 209/500 over, loss_G,loss_D= 4.829431056976318,0.07399319112300873
epoch 210/500 over, loss_G,loss_D= 4.706050872802734,0.09485193341970444
epoch 211/500 over, loss_G,loss_D= 4.962409973144531,0.017589816823601723
epoch 212/500 over, loss_G,loss_D= 5.395265579223633,0.11746890842914581
epoch 213/500 over, loss_G,loss_D= 4.412705421447754,0.18305771052837372
epoch 214/500 over, loss_G,loss_D= 4.978168487548828,0.07186895608901978
epoch 215/500 over, loss_G,loss_D= 5.316257476806641,0.06762771308422089
epoch 216/500 over, loss_G,loss_D= 4.756807804107666,0.08036336302757263
epoch 217/500 over, loss_G,loss_D= 4.764246940612793,0.21891051530838013
epoch 218/500 over, loss_G,loss_D= 4.903815269470215,0.05071776732802391
epoch 219/500 over, loss_G,loss_D= 4.622811794281006,0.10189476609230042
epoch 220/500 over, loss_G,loss_D= 4.973514080047607,0.026871196925640106
epoch 221/500 over, loss_G,loss_D= 4.4375786781311035,0.09462419897317886
epoch 222/500 over, loss_G,loss_D= 4.924927711486816,0.061411045491695404
epoch 223/500 over, loss_G,loss_D= 4.9383158683776855,0.04318348318338394
epoch 224/500 over, loss_G,loss_D= 5.295219421386719,0.04340614750981331
epoch 225/500 over, loss_G,loss_D= 5.06427526473999,0.05820965766906738
