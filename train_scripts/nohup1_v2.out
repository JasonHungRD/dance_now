nohup: ignoring input
img_1_1_keypoints-checkpoint.json not imported
Compose(
    Lambda()
    ToTensor()
    <class 'torch.FloatTensor'>
    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))
)
epoch 120/500 over, loss_G,loss_D= 3.5025341510772705,0.00921756960451603
1.train_bodystick.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  losses, out_img = big_model(torch.tensor(lbl_sample,dtype=torch.float32, device=torch.device('cuda:0'))
1.train_bodystick.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  ,torch.tensor(in_img,dtype=torch.float32, device=torch.device('cuda:0'))
/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
epoch 121/500 over, loss_G,loss_D= 3.4936773777008057,0.2433742731809616
epoch 122/500 over, loss_G,loss_D= 4.586483001708984,0.06394635140895844
epoch 123/500 over, loss_G,loss_D= 3.1947879791259766,0.008060149848461151
epoch 124/500 over, loss_G,loss_D= 3.357889175415039,0.006874857470393181
epoch 125/500 over, loss_G,loss_D= 3.620330810546875,0.011956405825912952
epoch 126/500 over, loss_G,loss_D= 3.1084866523742676,0.01767710968852043
epoch 127/500 over, loss_G,loss_D= 3.366744041442871,0.00579878268763423
epoch 128/500 over, loss_G,loss_D= 4.020271301269531,0.01337035559117794
epoch 129/500 over, loss_G,loss_D= 3.9534926414489746,0.013090571388602257
epoch 130/500 over, loss_G,loss_D= 3.4014816284179688,0.09807136654853821
epoch 131/500 over, loss_G,loss_D= 3.850740909576416,0.0151928486302495
epoch 132/500 over, loss_G,loss_D= 1.2821624279022217,0.613983154296875
epoch 133/500 over, loss_G,loss_D= 3.25305438041687,0.006419245153665543
epoch 134/500 over, loss_G,loss_D= 4.053300857543945,0.029469124972820282
epoch 135/500 over, loss_G,loss_D= 4.8454694747924805,0.046389538794755936
epoch 136/500 over, loss_G,loss_D= 3.8547282218933105,0.009335031732916832
epoch 137/500 over, loss_G,loss_D= 1.9114196300506592,0.46881523728370667
epoch 138/500 over, loss_G,loss_D= 3.4838829040527344,0.28881657123565674
epoch 139/500 over, loss_G,loss_D= 3.1647696495056152,0.030607499182224274
epoch 140/500 over, loss_G,loss_D= 3.277129888534546,0.032312121242284775
epoch 141/500 over, loss_G,loss_D= 3.461116313934326,0.07837843149900436
epoch 142/500 over, loss_G,loss_D= 3.6079626083374023,0.009671047329902649
epoch 143/500 over, loss_G,loss_D= 3.3708150386810303,0.00972718745470047
epoch 144/500 over, loss_G,loss_D= 4.157227516174316,0.013823021203279495
epoch 145/500 over, loss_G,loss_D= 3.7382819652557373,0.004840186331421137
epoch 146/500 over, loss_G,loss_D= 3.2915234565734863,0.027487603947520256
epoch 147/500 over, loss_G,loss_D= 3.7180089950561523,0.014438241720199585
epoch 148/500 over, loss_G,loss_D= 1.974182367324829,0.27651888132095337
epoch 149/500 over, loss_G,loss_D= 5.323330402374268,0.3363552987575531
epoch 150/500 over, loss_G,loss_D= 3.9738705158233643,0.01217710878700018
epoch 151/500 over, loss_G,loss_D= 3.318568706512451,0.0050713298842310905
epoch 152/500 over, loss_G,loss_D= 3.6173017024993896,0.0041008805856108665
epoch 153/500 over, loss_G,loss_D= 3.967646598815918,0.03823544457554817
epoch 154/500 over, loss_G,loss_D= 3.991111993789673,0.007909120991826057
epoch 155/500 over, loss_G,loss_D= 2.7082700729370117,0.15395212173461914
epoch 156/500 over, loss_G,loss_D= 3.522380828857422,0.005555837880820036
epoch 157/500 over, loss_G,loss_D= 3.5356221199035645,0.01414848305284977
epoch 158/500 over, loss_G,loss_D= 1.1852476596832275,0.5263810157775879
epoch 159/500 over, loss_G,loss_D= 3.3938727378845215,0.01196528971195221
epoch 160/500 over, loss_G,loss_D= 3.5057895183563232,0.007872559130191803
epoch 161/500 over, loss_G,loss_D= 3.4339332580566406,0.004876928403973579
epoch 162/500 over, loss_G,loss_D= 3.824112892150879,0.006258836947381496
epoch 163/500 over, loss_G,loss_D= 2.3301961421966553,0.3513650596141815
epoch 164/500 over, loss_G,loss_D= 3.839435338973999,0.007043641526252031
epoch 165/500 over, loss_G,loss_D= 3.3961896896362305,0.14803706109523773
epoch 166/500 over, loss_G,loss_D= 6.953766345977783,3.2991890907287598
epoch 167/500 over, loss_G,loss_D= 3.328218936920166,0.22791922092437744
epoch 168/500 over, loss_G,loss_D= 3.910922050476074,0.006752796471118927
epoch 169/500 over, loss_G,loss_D= 3.9194982051849365,0.015567085705697536
epoch 170/500 over, loss_G,loss_D= 4.539300918579102,0.036640822887420654
epoch 171/500 over, loss_G,loss_D= 3.7833285331726074,0.043968841433525085
epoch 172/500 over, loss_G,loss_D= 4.13370418548584,0.01983332261443138
epoch 173/500 over, loss_G,loss_D= 3.4423885345458984,0.003483025822788477
epoch 174/500 over, loss_G,loss_D= 3.487140655517578,0.027909979224205017
epoch 175/500 over, loss_G,loss_D= 3.7375216484069824,0.007613989058881998
epoch 176/500 over, loss_G,loss_D= 4.074272155761719,0.00793958455324173
epoch 177/500 over, loss_G,loss_D= 3.3079895973205566,0.0038694385439157486
epoch 178/500 over, loss_G,loss_D= 3.63535213470459,0.012665260583162308
epoch 179/500 over, loss_G,loss_D= 3.872488021850586,0.005782120395451784
epoch 180/500 over, loss_G,loss_D= 3.364462375640869,0.002556184772402048
epoch 181/500 over, loss_G,loss_D= 3.4117636680603027,0.007648203056305647
epoch 182/500 over, loss_G,loss_D= 3.3588569164276123,0.0033093716483563185
epoch 183/500 over, loss_G,loss_D= 3.9532649517059326,0.02682158723473549
epoch 184/500 over, loss_G,loss_D= 3.2549831867218018,0.0073842573910951614
epoch 185/500 over, loss_G,loss_D= 3.7501933574676514,0.011058492586016655
epoch 186/500 over, loss_G,loss_D= 4.017138481140137,0.023442024365067482
epoch 187/500 over, loss_G,loss_D= 2.4199113845825195,0.1451205462217331
epoch 188/500 over, loss_G,loss_D= 3.520019054412842,0.006458609364926815
epoch 189/500 over, loss_G,loss_D= 3.297342300415039,0.06381212919950485
epoch 190/500 over, loss_G,loss_D= 3.0308146476745605,0.008564339950680733
epoch 191/500 over, loss_G,loss_D= 3.1059656143188477,0.003820484969764948
epoch 192/500 over, loss_G,loss_D= 3.534453868865967,0.023050900548696518
epoch 193/500 over, loss_G,loss_D= 3.4476871490478516,0.008534813299775124
epoch 194/500 over, loss_G,loss_D= 1.904091477394104,0.17263518273830414
epoch 195/500 over, loss_G,loss_D= 2.448317050933838,0.06259827315807343
epoch 196/500 over, loss_G,loss_D= 3.2680838108062744,0.05486162379384041
epoch 197/500 over, loss_G,loss_D= 3.872124671936035,0.006436286028474569
epoch 198/500 over, loss_G,loss_D= 3.5783851146698,0.14590699970722198
epoch 199/500 over, loss_G,loss_D= 2.28049373626709,0.5396704077720642
epoch 200/500 over, loss_G,loss_D= 2.6115589141845703,0.32987380027770996
epoch 201/500 over, loss_G,loss_D= 3.6096043586730957,0.01936093345284462
epoch 202/500 over, loss_G,loss_D= 3.8178882598876953,0.0121000399813056
epoch 203/500 over, loss_G,loss_D= 3.3667945861816406,0.006151920650154352
epoch 204/500 over, loss_G,loss_D= 4.122418403625488,0.015625691041350365
epoch 205/500 over, loss_G,loss_D= 3.309053659439087,0.006878018379211426
epoch 206/500 over, loss_G,loss_D= 3.653268575668335,0.015762703493237495
epoch 207/500 over, loss_G,loss_D= 3.1741080284118652,0.0034961276687681675
epoch 208/500 over, loss_G,loss_D= 3.276676654815674,0.004269682802259922
epoch 209/500 over, loss_G,loss_D= 3.7257370948791504,0.017550401389598846
epoch 210/500 over, loss_G,loss_D= 3.7954046726226807,0.01069279108196497
epoch 211/500 over, loss_G,loss_D= 3.239016532897949,0.010080808773636818
epoch 212/500 over, loss_G,loss_D= 3.0200743675231934,0.003098273416981101
epoch 213/500 over, loss_G,loss_D= 3.168405532836914,0.0066721634939312935
epoch 214/500 over, loss_G,loss_D= 3.4383556842803955,0.0041747628711164
epoch 215/500 over, loss_G,loss_D= 3.5317275524139404,0.007139214314520359
epoch 216/500 over, loss_G,loss_D= 3.073136568069458,0.010661028325557709
epoch 217/500 over, loss_G,loss_D= 4.255126953125,0.01673721894621849
epoch 218/500 over, loss_G,loss_D= 2.939711093902588,0.0038972231559455395
epoch 219/500 over, loss_G,loss_D= 3.548579692840576,0.019733892753720284
